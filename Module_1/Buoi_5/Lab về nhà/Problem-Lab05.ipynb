{"cells":[{"cell_type":"markdown","metadata":{"id":"jxgT4r6ovuvd"},"source":["#Bài tập 1: Thao tác với ma trận  \n","**Lý thuyết**:  \n","NumPy cung cấp các công cụ mạnh mẽ để thao tác ma trận, bao gồm tính toán các định thức, tìm nghịch đảo và tính toán các giá trị riêng và vectơ riêng.\n","  \n","**Đề bài**:  \n","Tạo ma trận 5x5 ngẫu nhiên và thực hiện các thao tác sau:  \n","* Tính định thức (determinant) của ma trận.  \n","* Tìm nghịch đảo (transpose) của ma trận.  \n","* Tính các giá trị riêng (eigent value) và vectơ riêng (eigent vector) của ma trận.   \n","(Phần này sẽ liên quan tới đại số tuyến tính, mọi người có thể tự tìm hiểu để hiểu chi tiết về các khái niệm trên)\n","\n","<details>\n","  <summary>Hint</summary>\n","\n","```python\n","import numpy as np\n","\n","# Generate a random 5x5 matrix\n","matrix = np.random.rand(5, 5)\n","\n","# Compute determinant\n","det = np.linalg.det(matrix)\n","\n","# Find inverse\n","inverse = np.linalg.inv(matrix)\n","\n","# Calculate eigenvalues and eigenvectors\n","eigenvalues, eigenvectors = np.linalg.eig(matrix)\n","\n","```\n","</details>"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711943184294,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"},"user_tz":-420},"id":"-SEd8zd9tBN8"},"outputs":[{"name":"stdout","output_type":"stream","text":["matrix:\n","[[0.82703859 0.15840535 0.09561998 0.76521744 0.27587944]\n"," [0.67824417 0.40567751 0.84803476 0.77460683 0.04295375]\n"," [0.54007939 0.87171059 0.97122719 0.02118763 0.9831652 ]\n"," [0.05889724 0.13420184 0.55448344 0.39545755 0.96274772]\n"," [0.54743967 0.6386077  0.1197624  0.61175715 0.23797336]]\n","\n","determinant:\n","0.3381587667119999\n","\n","inverse:\n","[[ 1.75460764 -0.30007124  0.83450276 -1.0543411  -1.16214927]\n"," [-1.15148435 -0.13010436  0.16024274 -0.26570157  1.77128157]\n"," [-0.44173862  1.06419007  0.20017901  0.08674355 -0.85793442]\n"," [-0.47759695  0.50014452 -1.04715499  0.92804648  1.03510666]\n"," [ 0.50376214 -0.78185393  0.24144916  0.709069   -0.10687346]]\n","\n","eigenvalues:\n","[ 2.49232918+0.j         -0.294988  +0.64086079j -0.294988  -0.64086079j\n","  0.46751051+0.23245724j  0.46751051-0.23245724j]\n","\n","eigenvectors:\n","[[-0.31074664+0.j          0.10594602-0.14105623j  0.10594602+0.14105623j\n","   0.7326483 +0.j          0.7326483 -0.j        ]\n"," [-0.50023354+0.j          0.56177337+0.j          0.56177337-0.j\n","  -0.3021001 -0.07090988j -0.3021001 +0.07090988j]\n"," [-0.62859689+0.j         -0.47591345+0.16059755j -0.47591345-0.16059755j\n","  -0.33750505-0.30211145j -0.33750505+0.30211145j]\n"," [-0.36783691+0.j         -0.07731569+0.43736065j -0.07731569-0.43736065j\n","  -0.28126356+0.22705687j -0.28126356-0.22705687j]\n"," [-0.35037821+0.j         -0.04637751-0.44898903j -0.04637751+0.44898903j\n","   0.11579929+0.1329636j   0.11579929-0.1329636j ]]\n"]}],"source":["# Your code here\n","import numpy as np\n","\n","mat = np.random.rand(5, 5)\n","print('matrix:')\n","print(mat)\n","print()\n","\n","det = np.linalg.det(mat)\n","print('determinant:')\n","print(det)\n","print()\n","\n","inverse = np.linalg.inv(mat)\n","print('inverse:')\n","print(inverse)\n","print()\n","\n","eigenvalues, eigenvectors = np.linalg.eig(mat)\n","print('eigenvalues:')\n","print(eigenvalues)\n","print()\n","print('eigenvectors:')\n","print(eigenvectors)"]},{"cell_type":"markdown","metadata":{"id":"j5y16Eqkxd_o"},"source":["# Bài tập 2: Optimization\n","**Lý thuyết:**  \n","Gradient descent là một thuật toán tối ưu hóa được sử dụng để cực tiểu hóa hàm bằng cách di chuyển lặp đi lặp lại theo hướng dốc xuống.\n","\n","**Đề bài:**  \n","Triển khai gradient descent sử dụng NumPy để tối ưu hàm số sau:\n"," $$ f(x) = x^2 + 5 \\sin(x) $$\n","<details>\n","  <summary>Hint</summary>\n","\n","```python\n","import numpy as np\n","\n","def gradient_descent(x, learning_rate, iterations):\n","    for _ in range(iterations):\n","        gradient = 2*x + 5*np.cos(x)  # Đạo hàm riêng theo x\n","        x = x - learning_rate * gradient # Cập nhật tham số\n","    return x\n","\n","# Khởi tạo các hyperparameters\n","x_initial = 5  # Input đầu vào\n","learning_rate = 0.1 # Tốc độ học\n","iterations = 100 # Số lần lặp\n","\n","# Run gradient descent\n","minima = gradient_descent(x_initial, learning_rate, iterations)\n","```\n","\n","</details>"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711943686064,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"},"user_tz":-420},"id":"s3Q3kOnuwxxW"},"outputs":[{"name":"stdout","output_type":"stream","text":["-1.110510503581112\n"]}],"source":["# Your code here\n","\n","def gradient_descent (x, learning_rate, iterations):\n","    for _ in range(iterations):\n","        gradient = 2*x + 5*np.cos(x)\n","        x = x - learning_rate * gradient\n","    return x\n","\n","x_initial = 5\n","learning_rate = 0.1\n","iterations = 100\n","\n","x_min = gradient_descent(x_initial, learning_rate, iterations)\n","print(x_min)"]},{"cell_type":"markdown","metadata":{"id":"r9TwMgo-y5tm"},"source":["# Bài tập 3: Phân tích thống kê  \n","**Lý thuyết**:  \n","NumPy cung cấp các chức năng để phân tích thống kê, bao gồm tính toán giá trị trung bình (mean), trung vị (median), độ lệch chuẩn (standard deviation) và mối tương quan (correlation).  \n","\n","**Đề Bài**:  \n","Thực hiện phân tích thống kê trên tập dữ liệu bai3.csv bằng NumPy:  \n","* Tính giá trị trung bình, trung vị và độ lệch chuẩn của tập dữ liệu.\n","* Tính toán ma trận tương quan giữa các biến khác nhau.\n","* Xác định các ngoại lệ trong tập dữ liệu bằng cách sử dụng điểm z.\n","\n","<details>\n","  <summary>Hint</summary>\n","\n","```python\n","  # Load dataset\n","  data = np.loadtxt('dataset.csv', delimiter=',')\n","\n","  # Calculate mean, median, and standard deviation\n","  mean = np.mean(data, axis=0)\n","  median = np.median(data, axis=0)\n","  std_dev = np.std(data, axis=0)\n","\n","  # Compute correlation matrix\n","  correlation_matrix = np.corrcoef(data, rowvar=False)\n","\n","  # Identify outliers using z-scores\n","  z_scores = np.abs((data - mean) / std_dev)\n","  outliers = np.where(z_scores > 3)\n","```\n","</details>"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"KjYxequp1pld"},"outputs":[{"name":"stdout","output_type":"stream","text":["data:\n","[[1.2 3.5 4.8 2.1 5.6]\n"," [2.5 4.3 6.7 3.2 7.1]\n"," [3.1 2.9 5.4 1.8 6.3]\n"," [4.7 3.8 7.2 2.6 8.4]\n"," [5.6 4.6 8.3 3.9 9.2]]\n","\n","mean: [3.42 3.82 6.48 2.72 7.32]\n","\n","median: [3.1 3.8 6.7 2.6 7.1]\n","\n","standard deviation: [1.56639714 0.59799666 1.25443214 0.75736385 1.32272446]\n","\n","correlation matrix:\n","[[1.         0.47784764 0.89183434 0.61500461 0.94868903]\n"," [0.47784764 1.         0.81104187 0.97063145 0.71505798]\n"," [0.89183434 0.81104187 1.         0.88457426 0.98139657]\n"," [0.61500461 0.97063145 0.88457426 1.         0.79617986]\n"," [0.94868903 0.71505798 0.98139657 0.79617986 1.        ]]\n","\n","z-score: [[1.4172651  0.53512005 1.3392514  0.81862899 1.30034641]\n"," [0.58733509 0.80268007 0.17537816 0.63377728 0.16632338]\n"," [0.20429046 1.53847014 0.86094733 1.21473979 0.77113566]\n"," [0.81716186 0.033445   0.57396488 0.15844432 0.81649658]\n"," [1.39172879 1.30435512 1.45085568 1.55803581 1.42130886]]\n","\n","outliers:\n","(array([], dtype=int64), array([], dtype=int64))\n"]}],"source":["# Your code here\n","\n","data = np.loadtxt('bai3.csv', delimiter=',', skiprows=1)\n","print('data:')\n","print(data)\n","print()\n","\n","mean = np.mean(data, axis=0)\n","print('mean:', mean)\n","print()\n","\n","median = np.median(data, axis=0)\n","print('median:', median)\n","print()\n","\n","std_dev = np.std(data, axis=0)\n","print('standard deviation:', std_dev)\n","print()\n","\n","correlation = np.corrcoef(data, rowvar=False)\n","print('correlation matrix:')\n","print(correlation)\n","print()\n","\n","z_score = np.abs((data - mean)) / std_dev\n","print('z-score:', z_score)\n","print()\n","\n","outliers = np.where(z_score > 3)\n","print('outliers:')\n","print(outliers)"]},{"cell_type":"markdown","metadata":{"id":"ZX1eKlF805bM"},"source":["# Bài 4: Thao tác với tensor\n","Đề cho một tensor đại diện cho một hình ảnh thang độ xám. Thực hiện các thao tác sau:\n","\n","1. Reshape: Reshape tensor thành một hình dạng khác trong khi vẫn đảm bảo tổng số phần tử không đổi.\n","2. Transpose: Transpose tensor dọc theo các trục được chỉ định.\n","3. Slice: Trích xuất một tập hợp con của tensor bằng cách cắt dọc theo các kích thước được chỉ định.\n","4. Concatenate: Concatenate nhiều tensor dọc theo các trục được chỉ định.\n","5. Các phép toán theo phần tử: Thực hiện các phép toán theo phần tử như cộng, trừ, nhân và chia với các giá trị vô hướng hoặc các tensor khác.\n","6. Hoạt động rút gọn: Thực hiện các hoạt động rút gọn như tính tổng, trung bình, tối thiểu và tối đa dọc theo các trục được chỉ định.\n","7. Indexing: Truy cập các phần tử riêng lẻ hoặc các tensor phụ bằng cách sử dụng các chỉ số nguyên hoặc boolean mark.\n","\n","<details>\n","  <summary>Hint</summary>\n","\n","  ```python\n","    # 1. Reshape the tensor\n","    reshaped_tensor = image_tensor.reshape(1, 9)\n","\n","    # 2. Transpose the tensor\n","    transposed_tensor = image_tensor.T\n","\n","    # 3. Slice the tensor\n","    sliced_tensor = image_tensor[:2, :2]\n","\n","    # 4. Concatenate tensors\n","    concatenated_tensor = np.concatenate((image_tensor, image_tensor), axis=0)\n","\n","    # 5. Element-wise operations\n","    added_tensor = image_tensor + 0.1\n","    multiplied_tensor = image_tensor * 2\n","\n","    # 6. Reduction operations\n","    sum_tensor = np.sum(image_tensor)\n","    mean_tensor = np.mean(image_tensor, axis=0)\n","    max_tensor = np.max(image_tensor, axis=1)\n","\n","    # 7. Indexing\n","    element = image_tensor[1, 2]\n","  ```\n","</details>"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711944428036,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"},"user_tz":-420},"id":"sKx_zUMw041d"},"outputs":[],"source":["image_tensor = np.array([\n","    [0.1, 0.2, 0.3],\n","    [0.4, 0.5, 0.6],\n","    [0.7, 0.8, 0.9]\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### reshapre"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"aDy3tPzby5RN"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]]\n","[[[0.1 0.2 0.3]]\n","\n"," [[0.4 0.5 0.6]]\n","\n"," [[0.7 0.8 0.9]]]\n"]}],"source":["print(image_tensor.reshape(1, 9))\n","print(image_tensor.reshape(3, 1, 3))"]},{"cell_type":"markdown","metadata":{},"source":["### transpose"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.1 0.2 0.3]\n"," [0.4 0.5 0.6]\n"," [0.7 0.8 0.9]]\n","[[0.1 0.4 0.7]\n"," [0.2 0.5 0.8]\n"," [0.3 0.6 0.9]]\n","[[0.1 0.4 0.7]\n"," [0.2 0.5 0.8]\n"," [0.3 0.6 0.9]]\n"]}],"source":["print(np.transpose(image_tensor, axes=(0, 1)))\n","print(np.transpose(image_tensor, axes=(1, 0)))\n","print(image_tensor.T)"]},{"cell_type":"markdown","metadata":{},"source":["### slice"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.1 0.2]\n"," [0.4 0.5]]\n","[[0.5 0.6]\n"," [0.8 0.9]]\n","[[0.1 0.3]\n"," [0.7 0.9]]\n","[[0.7 0.8 0.9]\n"," [0.4 0.5 0.6]\n"," [0.1 0.2 0.3]]\n"]}],"source":["print(image_tensor[0:2, 0:2])\n","print(image_tensor[1:, 1:])\n","print(image_tensor[::2, ::2])\n","print(image_tensor[::-1, :])"]},{"cell_type":"markdown","metadata":{},"source":["### concatenate"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.1 0.2 0.3]\n"," [0.4 0.5 0.6]\n"," [0.7 0.8 0.9]\n"," [0.1 0.2 0.3]\n"," [0.4 0.5 0.6]\n"," [0.7 0.8 0.9]]\n","[[0.1 0.2 0.3 0.1 0.2 0.3]\n"," [0.4 0.5 0.6 0.4 0.5 0.6]\n"," [0.7 0.8 0.9 0.7 0.8 0.9]]\n"]}],"source":["print(np.concatenate((image_tensor, image_tensor), axis=0))\n","print(np.concatenate((image_tensor, image_tensor), axis=1))"]},{"cell_type":"markdown","metadata":{},"source":["### element-wise operations"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.1 1.2 1.3]\n"," [1.4 1.5 1.6]\n"," [1.7 1.8 1.9]]\n","[[0.2 0.4 0.6]\n"," [0.8 1.  1.2]\n"," [1.4 1.6 1.8]]\n"]}],"source":["print(image_tensor + 0.1)\n","print(image_tensor * 2)"]},{"cell_type":"markdown","metadata":{},"source":["### reduction operations"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4.5\n","[1.2 1.5 1.8]\n","[0.6 1.5 2.4]\n","0.9\n","[0.7 0.8 0.9]\n","[0.3 0.6 0.9]\n","0.1\n","[0.1 0.2 0.3]\n","[0.1 0.4 0.7]\n","0.5\n","[0.4 0.5 0.6]\n","[0.2 0.5 0.8]\n"]}],"source":["print(np.sum(image_tensor))\n","print(np.sum(image_tensor, axis=0))\n","print(np.sum(image_tensor, axis=1))\n","print(np.max(image_tensor))\n","print(np.max(image_tensor, axis=0))\n","print(np.max(image_tensor, axis=1))\n","print(np.min(image_tensor))\n","print(np.min(image_tensor, axis=0))\n","print(np.min(image_tensor, axis=1))\n","print(np.mean(image_tensor))\n","print(np.mean(image_tensor, axis=0))\n","print(np.mean(image_tensor, axis=1))"]},{"cell_type":"markdown","metadata":{},"source":["### indexing"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.1\n","0.6\n","[[False False False]\n"," [False False  True]\n"," [ True  True  True]]\n","[0.6 0.7 0.8 0.9]\n"]}],"source":["print(image_tensor[0, 0])\n","print(image_tensor[1][2])\n","boolean_index = image_tensor > 0.5\n","print(boolean_index)\n","print(image_tensor[boolean_index])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMk1q12/N28maJwPQwRv9wn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
